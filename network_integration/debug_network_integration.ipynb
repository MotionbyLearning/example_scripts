{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2, ncx2\n",
    "from matplotlib import pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "import matplotlib.colors as plc\n",
    "\n",
    "from depsi.network import form_network, arc_selection, remove_network_points_min_connections, _network_relation_matrix\n",
    "from depsi.arc_estimation import periodogram\n",
    "from depsi.mht_utils import pretest\n",
    "from depsi.network import _mht_network_adjustment, _solve_float_ambiguities\n",
    "\n",
    "# import dask\n",
    "# dask.config.set(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7feea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVELENGTH = 0.055465763  # Sentinel-1, in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all to memory\n",
    "stm = xr.open_zarr('../../data/stm_amsterdam_173p.zarr')\n",
    "\n",
    "# Remove the mother epoch\n",
    "idx_non_mother = np.squeeze(np.where(stm['h2ph_values'].mean(axis=0).values != 0)) # Mother image is with all h2ph values as 0\n",
    "stm = stm.isel(time = idx_non_mother)\n",
    "\n",
    "# For debugging, shorten the time series\n",
    "stm = stm.isel(time=slice(0, 30))\n",
    "stm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee14aec",
   "metadata": {},
   "source": [
    "## Step1: form network and remove arcs with low ensemble coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_arcs = form_network(stm, 'sd_phase', 'h2ph_values', 'years', max_length=0.001)\n",
    "stm_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010240d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(stm_arcs['uid'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x of sources and targets\n",
    "xx = np.stack([stm.isel(space = stm_arcs['source'])['lon'].values,\n",
    "               stm.isel(space = stm_arcs['target'])['lon'].values]).T\n",
    "# y of sources and targets\n",
    "yy = np.stack([stm.isel(space = stm_arcs['source'])['lat'].values,\n",
    "               stm.isel(space = stm_arcs['target'])['lat'].values]).T\n",
    "# Visualize created arcs\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(stm_arcs.sizes[\"space\"]):\n",
    "    ax.plot(xx[i], yy[i], color='b', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "phs_obs_unwrapped, ambigs, arc_height, arc_velo, ens_coh = periodogram(\n",
    "    stm_arcs,\n",
    "    \"d_phase\",\n",
    "    \"h2ph\",\n",
    "    \"Btemp\",\n",
    "    wavelength=WAVELENGTH,\n",
    ")\n",
    "\n",
    "stm_arcs[\"phs_obs_unwrapped\"] = phs_obs_unwrapped\n",
    "stm_arcs[\"ambigs\"] = ambigs\n",
    "stm_arcs[\"arc_height\"] = arc_height\n",
    "stm_arcs[\"arc_velo\"] = arc_velo\n",
    "stm_arcs[\"ens_coh\"] = ens_coh\n",
    "\n",
    "stm_arcs = stm_arcs.compute()\n",
    "stm_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba338e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x of sources and targets\n",
    "xx = np.stack([stm.isel(space = stm_arcs['source'])['lon'].values,\n",
    "               stm.isel(space = stm_arcs['target'])['lon'].values]).T\n",
    "# y of sources and targets\n",
    "yy = np.stack([stm.isel(space = stm_arcs['source'])['lat'].values,\n",
    "               stm.isel(space = stm_arcs['target'])['lat'].values]).T\n",
    "# Visualize created arcs\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.cm.rainbow\n",
    "norm = plc.Normalize(vmin=0, vmax=1.0)\n",
    "mean_nmad = np.abs(stm_arcs['ens_coh'].data)\n",
    "for i in range(stm_arcs.sizes[\"space\"]):\n",
    "    ax.plot(xx[i], yy[i], color=cmap(norm(mean_nmad[i])), linewidth=0.5)\n",
    "plt.title(\"Network STM arcs, colored by ens_coh\")\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax, label='ens_coh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select arcs with ens_coh > 0.5\n",
    "stm_arcs = arc_selection(stm_arcs, 0.75, 'ens_coh', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x of sources and targets\n",
    "xx = np.stack([stm.isel(space = stm_arcs['source'])['lon'].values,\n",
    "               stm.isel(space = stm_arcs['target'])['lon'].values]).T\n",
    "# y of sources and targets\n",
    "yy = np.stack([stm.isel(space = stm_arcs['source'])['lat'].values,\n",
    "               stm.isel(space = stm_arcs['target'])['lat'].values]).T\n",
    "# Visualize created arcs\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.cm.rainbow\n",
    "norm = plc.Normalize(vmin=0, vmax=1.0)\n",
    "mean_nmad = np.abs(stm_arcs['ens_coh'].data)\n",
    "for i in range(stm_arcs.sizes[\"space\"]):\n",
    "    ax.plot(xx[i], yy[i], color=cmap(norm(mean_nmad[i])), linewidth=0.5)\n",
    "plt.title(\"Network STM arcs, colored by ens_coh\")\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax, label='ens_coh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all points have at least 3 connections\n",
    "stm_step1 = stm.copy()\n",
    "stm_arcs_step1 = stm_arcs.copy()\n",
    "previous_size = -1  # Initialize with an impossible value to trigger the while loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eced8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep iterating until no more points are removed\n",
    "while stm_step1.sizes[\"space\"] != previous_size:\n",
    "    previous_size = stm_step1.sizes[\"space\"]\n",
    "    # Remove points with <=2 connections\n",
    "    stm_step1, stm_arcs_step1 = remove_network_points_min_connections(\n",
    "        stm_step1, stm_arcs_step1, min_connections=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x of sources and targets\n",
    "xx = np.stack([stm_step1.isel(space = stm_arcs_step1['source'])['lon'].values,\n",
    "               stm_step1.isel(space = stm_arcs_step1['target'])['lon'].values]).T\n",
    "# y of sources and targets\n",
    "yy = np.stack([stm_step1.isel(space = stm_arcs_step1['source'])['lat'].values,\n",
    "               stm_step1.isel(space = stm_arcs_step1['target'])['lat'].values]).T\n",
    "# Visualize created arcs\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.cm.rainbow\n",
    "norm = plc.Normalize(vmin=0, vmax=1.0)\n",
    "mean_nmad = np.abs(stm_arcs_step1['ens_coh'].data)\n",
    "for i in range(stm_arcs_step1.sizes[\"space\"]):\n",
    "    ax.plot(xx[i], yy[i], color=cmap(norm(mean_nmad[i])), linewidth=0.5)\n",
    "plt.title(\"Network STM arcs, colored by ens_coh\")\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax, label='ens_coh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf738312",
   "metadata": {},
   "source": [
    "## Step 2: MHT rejecting arcs/pnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netork relation matrix A\n",
    "A_sparse = _network_relation_matrix(stm_arcs_step1[\"source\"], stm_arcs_step1[\"target\"], stm_step1.sizes[\"space\"])\n",
    "\n",
    "# A_sparse = _network_relation_matrix(stm_arcs_step1[\"target\"], stm_arcs_step1[\"source\"], stm_step1.sizes[\"space\"])\n",
    "\n",
    "# Observations y\n",
    "y = stm_arcs_step1['ambigs'].data\n",
    "\n",
    "# Prepare stochastic model\n",
    "N_arcs = stm_arcs_step1.sizes[\"space\"]\n",
    "Qyy_diag = np.ones(N_arcs)\n",
    "invQy = scipy.sparse.diags(1/Qyy_diag, 0, shape=(N_arcs, N_arcs))\n",
    "\n",
    "# First estimation\n",
    "_, echeck = _solve_float_ambiguities(A_sparse, y, invQy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1aff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Model Test\n",
    "kOMT = 1e-10 # threshold\n",
    "OMT = (echeck.T @ invQy @ echeck).diagonal().sum()\n",
    "print(\"OMT:\", OMT)\n",
    "print(\"OMT > kOMT:\", OMT > kOMT) # if True, fail, need adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tests\n",
    "a0 = 0.1\n",
    "g0 = 0.5\n",
    "max_con = np.abs(A_sparse).sum(axis=0).max()\n",
    "\n",
    "kb_dict = {}\n",
    "\n",
    "for n_con in range(1, max_con+1):\n",
    "    _, k1, kb, _ = pretest(n_con, a0, g0)\n",
    "    kb_dict[n_con] = kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349caa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_network_echeck(pnt, arcs, echeck):\n",
    "    # Plot echeck for all arcs\n",
    "    # x of sources and targets\n",
    "    xx = np.stack([pnt.isel(space = arcs['source'])['lon'].values,\n",
    "                pnt.isel(space = arcs['target'])['lon'].values]).T\n",
    "    # y of sources and targets\n",
    "    yy = np.stack([pnt.isel(space = arcs['source'])['lat'].values,\n",
    "                pnt.isel(space = arcs['target'])['lat'].values]).T\n",
    "    # Visualize created arcs\n",
    "    fig, ax = plt.subplots()\n",
    "    cmap = plt.cm.rainbow\n",
    "    norm = plc.Normalize(vmin=0, vmax=10.0)\n",
    "    echeck_sum = echeck.sum(axis=1)\n",
    "    for i in range(arcs.sizes[\"space\"]):\n",
    "        ax.plot(xx[i], yy[i], color=cmap(echeck_sum[i]), linewidth=0.5)\n",
    "    ax.scatter(pnt['lon'], pnt['lat'], c='k', s=3)\n",
    "    plt.title(\"Network STM arcs, colored by echeck sum\")\n",
    "    plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax, label='echeck sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a860de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT1_THRES = 1 # Threshold for TT1, if TT1max < TT1_THRES, stop iteration\n",
    "TT1max = TT1_THRES + 1.0 # Initial TT1_max to trigger the while loop\n",
    "MAX_ITER = stm_arcs_step1.sizes[\"space\"] * stm_arcs_step1.sizes[\"time\"]\n",
    "stm_step2 = stm_step1.copy()\n",
    "stm_arcs_step2 = stm_arcs_step1.copy()\n",
    "niter = 0\n",
    "\n",
    "while (TT1max > TT1_THRES) and (OMT > kOMT) and (niter < MAX_ITER):\n",
    "    # In the loop, OMT fail\n",
    "    # Choose from two Ha: 1) remove an arc; 2) remove a point\n",
    "    flag_rm, idx_rm, TT1max, TTqmax = _mht_network_adjustment(A_sparse, y, Qyy_diag, k1, kb_dict)\n",
    "\n",
    "    if flag_rm == 0:  # remove arcs\n",
    "        stm_arcs_step2 = stm_arcs_step2.drop_isel(space=idx_rm)  # Remove the arc\n",
    "    elif flag_rm == 1:  # remove points\n",
    "        # Removing points is achieved by removing all arcs connects to the point\n",
    "        # Later the points will be actually removed when ensuring minimum connections\n",
    "        # Arc indices connecting to the point to remove\n",
    "        idx_arcs_selected = np.where(\n",
    "            (\n",
    "                (stm_arcs_step2[\"source\"] != idx_rm)\n",
    "                & (stm_arcs_step2[\"target\"] != idx_rm)\n",
    "            ).data\n",
    "        )[0] \n",
    "        # Remove all arcs connects to the point to remove\n",
    "        stm_arcs_step2 = stm_arcs_step2.isel(space=idx_arcs_selected)\n",
    "    \n",
    "    # Ensure all points have at least 3 connections\n",
    "    previous_size = -1  # Initialize with an impossible value to trigger the while loop\n",
    "    # Keep iterating until no more points are removed\n",
    "    while stm_step2.sizes[\"space\"] != previous_size:\n",
    "        previous_size = stm_step2.sizes[\"space\"]\n",
    "        # Remove points with <=2 connections\n",
    "        stm_step2, stm_arcs_step2 = remove_network_points_min_connections(\n",
    "            stm_step2, stm_arcs_step2, min_connections=3\n",
    "        )\n",
    "\n",
    "    # Get indices of selected arcs based on uid\n",
    "    idx_arcs_selected = np.where(stm_arcs_step2['uid'].isin(stm_arcs_step1['uid']))[0]\n",
    "\n",
    "    # Update the functional and stochastic model\n",
    "    Qyy_diag = Qyy_diag[idx_arcs_selected]\n",
    "    N_arcs = stm_arcs_step2.sizes[\"space\"]\n",
    "    invQy = scipy.sparse.diags(1 / Qyy_diag, 0, shape=(N_arcs, N_arcs))\n",
    "    A_sparse = _network_relation_matrix(\n",
    "        stm_arcs_step2[\"source\"],\n",
    "        stm_arcs_step2[\"target\"],\n",
    "        stm_step2.sizes[\"space\"],\n",
    "    )\n",
    "    \n",
    "    y = stm_arcs_step2[\"ambigs\"].data\n",
    "    \n",
    "\n",
    "    # Estimate residual again\n",
    "    _, echeck = _solve_float_ambiguities(A_sparse, y, invQy)\n",
    "\n",
    "    OMT = (echeck.T @ invQy @ echeck).diagonal().sum()\n",
    "\n",
    "    niter += 1\n",
    "    print(\n",
    "        f\"Iteration {niter}: OMT = {OMT}, flag_rm: {flag_rm}, TT1max: {TT1max}, TTqmax: {TTqmax}\"\n",
    "    )\n",
    "\n",
    "    visualize_network_echeck(stm_step2, stm_arcs_step2, echeck)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606d57b",
   "metadata": {},
   "source": [
    "## Step 3: fix ambiguity errors per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be46913",
   "metadata": {},
   "outputs": [],
   "source": [
    "kOMT = 1e-7 # threshold for each epoch, changed from 1e-10 to avoid repeatively fixing several same arcs\n",
    "\n",
    "# Fix unwrapping ambiguities by looping over epochs\n",
    "stm_arcs_step3 = stm_arcs_step2.copy()\n",
    "stm_step3 = stm_step2.copy()\n",
    "estimated_ambigs = np.zeros((stm_step3.sizes[\"space\"], stm_step3.sizes[\"time\"]))\n",
    "for epoch in range(stm_step2.sizes[\"time\"]):\n",
    "    y = stm_arcs_step2[\"ambigs\"].isel(time=epoch).data\n",
    "    acheck_ifg, echeck_ifg = _solve_float_ambiguities(A_sparse, y, invQy)\n",
    "    OMT = echeck_ifg.T @ invQy @ echeck_ifg\n",
    "    print(f\"Epoch {epoch}, updated OMT: {OMT}\")\n",
    "\n",
    "    idx_previous_arc_fix = -1 # Avoid fixing the same arc again in the same epoch\n",
    "\n",
    "    while OMT > kOMT: # While OMT fail, fix for this epoch\n",
    "        # Find arc index with largest abs echeck\n",
    "        # When OMT > kOMT, echeck_ifg[idx_max_echeck] is guaranteed to be non-zero\n",
    "        idx_sort = np.argsort(np.abs(echeck_ifg))[::-1] # Indices of echeck sorted by abs value, descending\n",
    "        idx_max_echeck = idx_sort[0] # Index of arc with largest abs echeck\n",
    "        if idx_max_echeck == idx_previous_arc_fix:\n",
    "            # If get same arc as previous fix, take the second largest\n",
    "            idx_max_echeck = idx_sort[1]\n",
    "        \n",
    "        if np.round(abs(echeck_ifg[idx_max_echeck])) >= 1: # If >= 1, minus closest integer\n",
    "            y[idx_max_echeck] -= np.round(echeck_ifg[idx_max_echeck])\n",
    "        elif echeck_ifg[idx_max_echeck] > 0: # if (0, 1), minus 1\n",
    "            y[idx_max_echeck] -= 1.0\n",
    "        elif echeck_ifg[idx_max_echeck] < 0: # if (-1, 0), plus 1\n",
    "            y[idx_max_echeck] += 1.0\n",
    "        \n",
    "        idx_previous_arc_fix = idx_max_echeck # record the fixed arc index\n",
    "\n",
    "        # Recalculate OMT\n",
    "        acheck_ifg, echeck_ifg = _solve_float_ambiguities(A_sparse, y, invQy)\n",
    "        OMT = echeck_ifg.T @ invQy @ echeck_ifg\n",
    "        print(f\"Epoch {epoch}, updated OMT: {OMT}, idx_fixed_arc: {idx_max_echeck}\")\n",
    "    \n",
    "    # Update the ambiguities for arcs and stm points\n",
    "    stm_arcs_step3[\"ambigs\"].data[:, epoch] = y\n",
    "\n",
    "    # Assign \n",
    "    estimated_ambigs[:, epoch] = acheck_ifg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CHECK estimated_ambigs\n",
    "# This value should be all close to integers since we have fixed arc ambiguities\n",
    "estimated_ambigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the estimated ambiguities to nearest integer and assign to stm_step3\n",
    "stm_step3[\"estimated_ambigs\"] = ((\"space\", \"time\"), np.round(estimated_ambigs))\n",
    "\n",
    "# Visualize the estimated ambiguities\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(estimated_ambigs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b49fa4",
   "metadata": {},
   "source": [
    "## Step 4: estimate the unwrapped phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use _solve_float_ambiguities function, but it should be renamed to a more general name\n",
    "psc_phase, _ = _solve_float_ambiguities(A_sparse, stm_arcs_step3['d_phase'].data, invQy) \n",
    "psc_phase_unw = 2*np.pi*estimated_ambigs+psc_phase\n",
    "stm_step3[\"psc_phase_unw\"] = ((\"space\", \"time\"), psc_phase_unw)\n",
    "\n",
    "# visualize unwrapped phase\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(psc_phase_unw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee81036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one pnt wrapped and unwrapped phase\n",
    "pnt_id = 25\n",
    "stm_1pnt = stm_step3.isel(space = pnt_id)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "#plot without line\n",
    "ax.plot(stm_1pnt[\"years\"].data, stm_1pnt[\"sd_phase\"].data+2*np.pi, marker='.', linestyle='None', color='gray',)\n",
    "ax.plot(stm_1pnt[\"years\"].data, stm_1pnt[\"sd_phase\"].data-2*np.pi, marker='.', linestyle='None', color='gray',)\n",
    "ax.plot(stm_1pnt[\"years\"].data, stm_1pnt[\"psc_phase_unw\"], marker='.', color='red', linewidth=0.5, label='Unwrapped phase')\n",
    "ax.plot(stm_1pnt[\"years\"].data, stm_1pnt[\"sd_phase\"].data, color='blue', linewidth=0.5, label='Wrapped phase')\n",
    "ax.set_ylabel('Phase [rad]')\n",
    "ax.set_xlabel('Time [years]')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb2103",
   "metadata": {},
   "source": [
    "## Step 5: Model estimation (TBC)\n",
    "\n",
    "This can be implemented as a separate function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depsi-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
